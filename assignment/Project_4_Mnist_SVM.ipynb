{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_DOhVC8TeaG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aSb8Ij5ThJC",
        "outputId": "cc5c226c-581c-4745-a024-8cec42614163"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "# Load the MNIST dataset\n",
        "mnist = fetch_openml('mnist_784', version=1, cache=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luI7umd0T2q3"
      },
      "outputs": [],
      "source": [
        "# Prepare the data\n",
        "X = mnist.data.astype('float32')\n",
        "y = mnist.target.astype('int64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rh5jYc4aU8ql"
      },
      "outputs": [],
      "source": [
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5h80ePOVVRU"
      },
      "outputs": [],
      "source": [
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iy6ppvgyVYSk"
      },
      "outputs": [],
      "source": [
        "# Define the SVM classifier\n",
        "svm_clf = SVC()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JCYKpcpVbqb"
      },
      "outputs": [],
      "source": [
        "# Define parameter grid for grid search\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XsPV9ilrVm3T"
      },
      "outputs": [],
      "source": [
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(svm_clf, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfIXKsSSVoCP"
      },
      "outputs": [],
      "source": [
        "# Get the best model from grid search\n",
        "best_svm = grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16WHSyTnVvLQ"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_pred = best_svm.predict(X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5bOj6mjVxy_"
      },
      "outputs": [],
      "source": [
        "# Evaluate performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sffxvqtaVz3G"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cEv58rAV2Xs"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=2)\n",
        "X_train_reduced = pca.fit_transform(X_train_scaled)\n",
        "\n",
        "# Train the SVM classifier with reduced dimensionality data\n",
        "svm_clf.fit(X_train_reduced, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UXO_2jyV5Z0"
      },
      "outputs": [],
      "source": [
        "# Visualize decision boundary\n",
        "def plot_decision_boundary(clf, X, y):\n",
        "    h = .02  # step size in the mesh\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                         np.arange(y_min, y_max, h))\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCVvMoyWV8hu"
      },
      "outputs": [],
      "source": [
        "    Z = Z.reshape(xx.shape)\n",
        "# Put the result into a color plot\n",
        "    plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "\n",
        "    # Plot the training points\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm, edgecolors='k')\n",
        "    plt.xlabel('Principal Component 1')\n",
        "    plt.ylabel('Principal Component 2')\n",
        "    plt.title('Decision Boundary Visualization')\n",
        "    plt.show()\n",
        "\n",
        "plot_decision_boundary(svm_clf, X_train_reduced, y_train)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}