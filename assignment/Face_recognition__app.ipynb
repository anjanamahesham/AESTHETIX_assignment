{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHLYAZ6zXz7l"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms,models\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision"
      ],
      "metadata": {
        "id": "o9IL3jWld9Mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir='/content/drive/MyDrive/Project'"
      ],
      "metadata": {
        "id": "Eu_qD-xvX4Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms={\n",
        "    'train':transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "    ]),\n",
        "\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "    ])\n",
        "    }"
      ],
      "metadata": {
        "id": "f5VcO5K6aom1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_datasets={x:datasets.ImageFolder(root=data_dir,transform=data_transforms[x])\n",
        "                for x in ['train','val']}\n"
      ],
      "metadata": {
        "id": "o-qgcJjohbBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloaders={x:DataLoader(image_datasets[x],batch_size=2,shuffle=True,num_workers=4)\n",
        "                for x in ['train','val']}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZamtJlmMheRu",
        "outputId": "059351ca-130c-4f85-fe1e-91d7aead1782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class face_recognition(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(face_recognition,self).__init__()\n",
        "    self.model=models.resnet18(pretrained=True)\n",
        "    num_ftrs=self.model.fc.in_features\n",
        "    self.model.fc=nn.Linear(num_ftrs,2)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.model(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "aYFs4Pncgmtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=face_recognition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmfVwpcbh2K8",
        "outputId": "d5fe7ac0-33a2-4341-958e-c24ffa3a9c8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion=nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "KPcZv9rth79x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer=optim.SGD(model.parameters(),lr=0.001)"
      ],
      "metadata": {
        "id": "qyHrT6WpiAEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model,critetion,optimizer,num_epochs=10):\n",
        "  for epoch in range(num_epochs):\n",
        "    print(f'Epoch{epoch}/{num_epochs-1}')\n",
        "    print('-'*10)\n",
        "\n",
        "  for phase in ['train','val']:\n",
        "    if phase == 'train':\n",
        "      model.train()\n",
        "    else:\n",
        "      model.eval()\n",
        "    running_loss=0.0\n",
        "    running_corrects=0\n",
        "\n",
        "    for inputs, labels in dataloaders[phase]:\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      with torch.set_grad_enabled(phase=='train'):\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs,1)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        if phase == 'train':\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()* inputs.size(0)\n",
        "        running_corrects += torch.sum(preds==labels.data)\n",
        "      epoch_loss=running_loss / len(image_datasets[phase])\n",
        "      epoch_acc = running_corrects.double()/len(image_datasets[phase])\n",
        "\n",
        "      print(f'{phase} Loss: {epoch_loss: .4f} Acc: {epoch_acc:.4f}')\n"
      ],
      "metadata": {
        "id": "hUvgSABiiCWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model=model.to(device)\n",
        "train_model(model,criterion,optimizer,num_epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1zkLtcViLSB",
        "outputId": "1eafc1ab-04ee-4374-b10e-1f350cb1977a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch0/9\n",
            "----------\n",
            "Epoch1/9\n",
            "----------\n",
            "Epoch2/9\n",
            "----------\n",
            "Epoch3/9\n",
            "----------\n",
            "Epoch4/9\n",
            "----------\n",
            "Epoch5/9\n",
            "----------\n",
            "Epoch6/9\n",
            "----------\n",
            "Epoch7/9\n",
            "----------\n",
            "Epoch8/9\n",
            "----------\n",
            "Epoch9/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss:  0.0175 Acc: 0.0000\n",
            "train Loss:  0.0325 Acc: 0.0000\n",
            "train Loss:  0.0440 Acc: 0.0100\n",
            "train Loss:  0.0572 Acc: 0.0200\n",
            "train Loss:  0.0659 Acc: 0.0400\n",
            "train Loss:  0.0734 Acc: 0.0600\n",
            "train Loss:  0.0790 Acc: 0.0800\n",
            "train Loss:  0.0988 Acc: 0.0900\n",
            "train Loss:  0.1265 Acc: 0.0900\n",
            "train Loss:  0.1461 Acc: 0.0900\n",
            "train Loss:  0.1638 Acc: 0.0900\n",
            "train Loss:  0.1742 Acc: 0.1100\n",
            "train Loss:  0.1898 Acc: 0.1200\n",
            "train Loss:  0.2074 Acc: 0.1200\n",
            "train Loss:  0.2223 Acc: 0.1300\n",
            "train Loss:  0.2342 Acc: 0.1500\n",
            "train Loss:  0.2545 Acc: 0.1600\n",
            "train Loss:  0.2661 Acc: 0.1800\n",
            "train Loss:  0.2796 Acc: 0.1900\n",
            "train Loss:  0.2917 Acc: 0.2000\n",
            "train Loss:  0.3030 Acc: 0.2100\n",
            "train Loss:  0.3214 Acc: 0.2200\n",
            "train Loss:  0.3434 Acc: 0.2200\n",
            "train Loss:  0.3623 Acc: 0.2200\n",
            "train Loss:  0.3759 Acc: 0.2300\n",
            "train Loss:  0.3862 Acc: 0.2500\n",
            "train Loss:  0.3968 Acc: 0.2700\n",
            "train Loss:  0.4196 Acc: 0.2700\n",
            "train Loss:  0.4344 Acc: 0.2800\n",
            "train Loss:  0.4474 Acc: 0.2900\n",
            "train Loss:  0.4663 Acc: 0.2900\n",
            "train Loss:  0.4765 Acc: 0.3100\n",
            "train Loss:  0.4864 Acc: 0.3300\n",
            "train Loss:  0.5021 Acc: 0.3400\n",
            "train Loss:  0.5147 Acc: 0.3500\n",
            "train Loss:  0.5305 Acc: 0.3600\n",
            "train Loss:  0.5453 Acc: 0.3700\n",
            "train Loss:  0.5549 Acc: 0.3900\n",
            "train Loss:  0.5692 Acc: 0.4000\n",
            "train Loss:  0.5793 Acc: 0.4200\n",
            "train Loss:  0.5923 Acc: 0.4300\n",
            "train Loss:  0.6012 Acc: 0.4500\n",
            "train Loss:  0.6080 Acc: 0.4700\n",
            "train Loss:  0.6194 Acc: 0.4800\n",
            "train Loss:  0.6256 Acc: 0.5000\n",
            "train Loss:  0.6430 Acc: 0.5100\n",
            "train Loss:  0.6545 Acc: 0.5200\n",
            "train Loss:  0.6775 Acc: 0.5200\n",
            "train Loss:  0.6939 Acc: 0.5200\n",
            "train Loss:  0.7086 Acc: 0.5300\n",
            "val Loss:  0.0088 Acc: 0.0200\n",
            "val Loss:  0.0226 Acc: 0.0300\n",
            "val Loss:  0.0468 Acc: 0.0300\n",
            "val Loss:  0.0634 Acc: 0.0400\n",
            "val Loss:  0.0798 Acc: 0.0500\n",
            "val Loss:  0.0937 Acc: 0.0600\n",
            "val Loss:  0.1036 Acc: 0.0700\n",
            "val Loss:  0.1151 Acc: 0.0800\n",
            "val Loss:  0.1244 Acc: 0.1000\n",
            "val Loss:  0.1279 Acc: 0.1200\n",
            "val Loss:  0.1476 Acc: 0.1300\n",
            "val Loss:  0.1578 Acc: 0.1400\n",
            "val Loss:  0.1675 Acc: 0.1600\n",
            "val Loss:  0.1764 Acc: 0.1800\n",
            "val Loss:  0.1953 Acc: 0.1900\n",
            "val Loss:  0.2019 Acc: 0.2100\n",
            "val Loss:  0.2103 Acc: 0.2300\n",
            "val Loss:  0.2354 Acc: 0.2300\n",
            "val Loss:  0.2425 Acc: 0.2500\n",
            "val Loss:  0.2484 Acc: 0.2700\n",
            "val Loss:  0.2514 Acc: 0.2900\n",
            "val Loss:  0.2600 Acc: 0.3100\n",
            "val Loss:  0.2760 Acc: 0.3100\n",
            "val Loss:  0.2959 Acc: 0.3100\n",
            "val Loss:  0.3087 Acc: 0.3200\n",
            "val Loss:  0.3225 Acc: 0.3300\n",
            "val Loss:  0.3356 Acc: 0.3400\n",
            "val Loss:  0.3526 Acc: 0.3500\n",
            "val Loss:  0.3621 Acc: 0.3700\n",
            "val Loss:  0.3747 Acc: 0.3800\n",
            "val Loss:  0.3905 Acc: 0.3900\n",
            "val Loss:  0.4024 Acc: 0.4000\n",
            "val Loss:  0.4076 Acc: 0.4200\n",
            "val Loss:  0.4156 Acc: 0.4400\n",
            "val Loss:  0.4258 Acc: 0.4600\n",
            "val Loss:  0.4388 Acc: 0.4700\n",
            "val Loss:  0.4525 Acc: 0.4800\n",
            "val Loss:  0.4603 Acc: 0.5000\n",
            "val Loss:  0.4654 Acc: 0.5200\n",
            "val Loss:  0.4855 Acc: 0.5300\n",
            "val Loss:  0.5004 Acc: 0.5400\n",
            "val Loss:  0.5147 Acc: 0.5500\n",
            "val Loss:  0.5246 Acc: 0.5600\n",
            "val Loss:  0.5350 Acc: 0.5700\n",
            "val Loss:  0.5503 Acc: 0.5800\n",
            "val Loss:  0.5611 Acc: 0.6000\n",
            "val Loss:  0.5652 Acc: 0.6200\n",
            "val Loss:  0.5769 Acc: 0.6300\n",
            "val Loss:  0.5889 Acc: 0.6500\n",
            "val Loss:  0.6053 Acc: 0.6600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model,'/content/drive/MyDrive/trained')"
      ],
      "metadata": {
        "id": "-SHJdMvqiOoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Define the device (CPU or GPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load the saved model\n",
        "model = torch.load('/content/drive/MyDrive/trained')\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Define the transformations for the new image\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "1eIuqeLcjbjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the new image\n",
        "image_path_1 = '/content/236A7806.JPG'\n",
        "image = Image.open(image_path_1)\n",
        "\n",
        "# Preprocess the image\n",
        "input_image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "# Perform inference\n",
        "with torch.no_grad():\n",
        "    output = model(input_image)\n",
        "    probabilities = torch.softmax(output, dim=1)\n",
        "    predicted_class = torch.argmax(probabilities, dim=1).item()\n",
        "\n",
        "# Convert class index to class label (assuming class 0 is \"lemon\" and class 1 is \"melon\")\n",
        "class_labels = [\"Anju\", \"Zanvi\"]\n",
        "predicted_label = class_labels[predicted_class]\n",
        "\n",
        "print(\"Predicted class:\", predicted_label)\n",
        "print(\"Probabilities:\", probabilities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9DTMI75jl1x",
        "outputId": "58be42ae-6c5d-4078-9467-818719f6277b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: Zanvi\n",
            "Probabilities: tensor([[0.3051, 0.6949]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the new image\n",
        "image_path_1 = '/content/DSC_0319.JPG'\n",
        "image = Image.open(image_path_1)\n",
        "\n",
        "# Preprocess the image\n",
        "input_image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "# Perform inference\n",
        "with torch.no_grad():\n",
        "    output = model(input_image)\n",
        "    probabilities = torch.softmax(output, dim=1)\n",
        "    predicted_class = torch.argmax(probabilities, dim=1).item()\n",
        "\n",
        "\n",
        "class_labels = [\"Anju\", \"Zanvi\"]\n",
        "predicted_label = class_labels[predicted_class]\n",
        "\n",
        "print(\"Predicted class:\", predicted_label)\n",
        "print(\"Probabilities:\", probabilities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2Gm24Kvk3PH",
        "outputId": "bf94ffa6-357d-4e39-f7af-8aea37ad128b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: Anju\n",
            "Probabilities: tensor([[0.5423, 0.4577]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the new image\n",
        "image_path_1 = '/content/236A7806.JPG'\n",
        "image = Image.open(image_path_1)\n",
        "\n",
        "# Preprocess the image\n",
        "input_image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "# Perform inference\n",
        "with torch.no_grad():\n",
        "    output = model(input_image)\n",
        "    probabilities = torch.softmax(output, dim=1)\n",
        "    predicted_class = torch.argmax(probabilities, dim=1).item()\n",
        "\n",
        "\n",
        "class_labels = [\"Anju\", \"Zanvi\"]\n",
        "predicted_label = class_labels[predicted_class]\n",
        "\n",
        "print(\"Predicted class:\", predicted_label)\n",
        "print(\"Probabilities:\", probabilities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRaE39zql08W",
        "outputId": "7ed50853-f018-4842-a350-23f18441b3c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: Zanvi\n",
            "Probabilities: tensor([[0.3051, 0.6949]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the new image\n",
        "image_path_1 = '/content/DSC_0634.JPG'\n",
        "image = Image.open(image_path_1)\n",
        "\n",
        "# Preprocess the image\n",
        "input_image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "# Perform inference\n",
        "with torch.no_grad():\n",
        "    output = model(input_image)\n",
        "    probabilities = torch.softmax(output, dim=1)\n",
        "    predicted_class = torch.argmax(probabilities, dim=1).item()\n",
        "\n",
        "\n",
        "class_labels = [\"Anju\", \"Zanvi\"]\n",
        "predicted_label = class_labels[predicted_class]\n",
        "\n",
        "print(\"Predicted class:\", predicted_label)\n",
        "print(\"Probabilities:\", probabilities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syOiJlfWTDjg",
        "outputId": "67959673-cff6-4eda-e6da-8ad96ae7dc4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: Zanvi\n",
            "Probabilities: tensor([[0.3521, 0.6479]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6jfPAPj3Twne"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}